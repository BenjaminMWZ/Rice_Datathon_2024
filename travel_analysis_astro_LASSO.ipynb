{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  game_date home_team away_team  is_day_game  home_score  \\\n",
      "19          19   20000404       PIT       HOU        False           2   \n",
      "32          32   20000405       PIT       HOU        False           2   \n",
      "46          46   20000406       PIT       HOU         True          10   \n",
      "57          57   20000407       HOU       PHI        False           1   \n",
      "72          72   20000408       HOU       PHI         True           8   \n",
      "\n",
      "    away_score  venue            venue_name        city  ... away_hbp  \\\n",
      "19           5  PIT07  Three Rivers Stadium  Pittsburgh  ...        0   \n",
      "32          11  PIT07  Three Rivers Stadium  Pittsburgh  ...        0   \n",
      "46           1  PIT07  Three Rivers Stadium  Pittsburgh  ...        0   \n",
      "57           4  HOU03      Minute Maid Park     Houston  ...        0   \n",
      "72           5  HOU03      Minute Maid Park     Houston  ...        1   \n",
      "\n",
      "    home_pa  home_1b  home_2b  home_3b  home_hr  home_fo  home_so  home_bb  \\\n",
      "19       36        5        0        0        1       21        5        3   \n",
      "32       38        7        2        0        0       24        2        3   \n",
      "46       44        9        4        1        2       15        9        4   \n",
      "57       32        4        0        0        1       20        5        2   \n",
      "72       38        6        1        2        2       19        5        3   \n",
      "\n",
      "    home_hbp  \n",
      "19         1  \n",
      "32         0  \n",
      "46         0  \n",
      "57         0  \n",
      "72         0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "file_path = './datathon_2024_dataset_corrected.csv'\n",
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "original_df = pd.read_csv(file_path)\n",
    "\n",
    "# Only keep home_team or away_team equals HOU\n",
    "astro_df = original_df.loc[(original_df['home_team'] == 'HOU') | (original_df['away_team'] == 'HOU')]\n",
    "\n",
    "print(astro_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read location file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         city  latitude  longitude\n",
      "0     Atlanta   33.7490   -84.3880\n",
      "1  Cincinnati   39.1031   -84.5120\n",
      "2       Miami   25.7617   -80.1918\n",
      "3    Montreal   45.5017   -73.5673\n",
      "4    New York   40.7128   -74.0060\n"
     ]
    }
   ],
   "source": [
    "location_file_path = './cities_coordinates.xlsx'\n",
    "location_df = pd.read_excel(location_file_path)\n",
    "print(location_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the distance with latitudes and longitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance is：559.12 \n"
     ]
    }
   ],
   "source": [
    "# Calculate the distance between two points.\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # 将经纬度转换为弧度\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine公式\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # 地球半径（单位：公里）\n",
    "    radius = 6371.0\n",
    "\n",
    "    # 计算距离\n",
    "    distance = radius * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "# 示例：两个地点的经纬度\n",
    "lat1, lon1 = 37.7749, -122.4194  # 地点1（例如，旧金山）\n",
    "lat2, lon2 = 34.0522, -118.2437  # 地点2（例如，洛杉矶）\n",
    "\n",
    "# 计算距离\n",
    "result = haversine(lat1, lon1, lat2, lon2)\n",
    "print(f\"distance is：{result:.2f} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete outlier cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out all city names\n",
    "\n",
    "# Delelete all rows with city \"Tokyo\", \"London\", \"Sydney\",  \"San Juan\", \"Monterrey\"\n",
    "astro_df = astro_df[astro_df['city'] != 'Tokyo']\n",
    "astro_df = astro_df[astro_df['city'] != 'London']\n",
    "astro_df = astro_df[astro_df['city'] != 'Sydney']\n",
    "astro_df = astro_df[astro_df['city'] != 'San Juan']\n",
    "astro_df = astro_df[astro_df['city'] != 'Monterrey']\n",
    "\n",
    "# print(original_df['city'].unique())\n",
    "\n",
    "# Count the number of unique city\n",
    "# print(original_df['city'].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add location to original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  game_date home_team away_team  is_day_game  home_score  \\\n",
      "0             19   20000404       PIT       HOU        False           2   \n",
      "1             32   20000405       PIT       HOU        False           2   \n",
      "2             46   20000406       PIT       HOU         True          10   \n",
      "114           57   20000407       HOU       PHI        False           1   \n",
      "115           72   20000408       HOU       PHI         True           8   \n",
      "116           87   20000409       HOU       PHI         True           2   \n",
      "117           99   20000410       HOU       SLN        False           7   \n",
      "118          107   20000411       HOU       SLN        False           6   \n",
      "119          119   20000412       HOU       SLN        False           7   \n",
      "1999         150   20000414       SDN       HOU        False           4   \n",
      "2000         163   20000415       SDN       HOU        False           5   \n",
      "2001         179   20000416       SDN       HOU         True          13   \n",
      "2055         196   20000418       LAN       HOU        False           5   \n",
      "2056         210   20000419       LAN       HOU        False           3   \n",
      "120          236   20000421       HOU       SDN        False           2   \n",
      "121          249   20000422       HOU       SDN         True           6   \n",
      "122          264   20000423       HOU       SDN         True          10   \n",
      "123          284   20000425       HOU       CHN        False          11   \n",
      "124          299   20000426       HOU       CHN        False           8   \n",
      "125          313   20000427       HOU       CHN         True           3   \n",
      "\n",
      "      away_score  venue            venue_name         city  ... home_1b  \\\n",
      "0              5  PIT07  Three Rivers Stadium   Pittsburgh  ...       5   \n",
      "1             11  PIT07  Three Rivers Stadium   Pittsburgh  ...       7   \n",
      "2              1  PIT07  Three Rivers Stadium   Pittsburgh  ...       9   \n",
      "114            4  HOU03      Minute Maid Park      Houston  ...       4   \n",
      "115            5  HOU03      Minute Maid Park      Houston  ...       6   \n",
      "116            3  HOU03      Minute Maid Park      Houston  ...       4   \n",
      "117            8  HOU03      Minute Maid Park      Houston  ...       2   \n",
      "118           10  HOU03      Minute Maid Park      Houston  ...       4   \n",
      "119            5  HOU03      Minute Maid Park      Houston  ...       3   \n",
      "1999          10  SAN01      Qualcomm Stadium    San Diego  ...       9   \n",
      "2000           3  SAN01      Qualcomm Stadium    San Diego  ...       5   \n",
      "2001           3  SAN01      Qualcomm Stadium    San Diego  ...      15   \n",
      "2055           3  LOS03        Dodger Stadium  Los Angeles  ...       3   \n",
      "2056          10  LOS03        Dodger Stadium  Los Angeles  ...       4   \n",
      "120            7  HOU03      Minute Maid Park      Houston  ...       4   \n",
      "121            8  HOU03      Minute Maid Park      Houston  ...       1   \n",
      "122           11  HOU03      Minute Maid Park      Houston  ...       5   \n",
      "123            7  HOU03      Minute Maid Park      Houston  ...      10   \n",
      "124           13  HOU03      Minute Maid Park      Houston  ...       7   \n",
      "125           12  HOU03      Minute Maid Park      Houston  ...       3   \n",
      "\n",
      "      home_2b  home_3b  home_hr  home_fo  home_so  home_bb  home_hbp  \\\n",
      "0           0        0        1       21        5        3         1   \n",
      "1           2        0        0       24        2        3         0   \n",
      "2           4        1        2       15        9        4         0   \n",
      "114         0        0        1       20        5        2         0   \n",
      "115         1        2        2       19        5        3         0   \n",
      "116         1        0        0       18        7        6         1   \n",
      "117         1        0        4       18        7        3         1   \n",
      "118         1        1        2       19        7        2         1   \n",
      "119         3        0        3       13       10        5         0   \n",
      "1999        3        1        0       20        5        1         0   \n",
      "2000        2        0        2       17        6        4         0   \n",
      "2001        1        0        2       15        8        2         2   \n",
      "2055        2        0        3       11       13        2         1   \n",
      "2056        1        0        2       19        8        4         0   \n",
      "120         1        0        1       17        9        7         0   \n",
      "121         3        0        2       16       14        7         2   \n",
      "122         2        0        3       18        8        3         2   \n",
      "123         5        0        1       16        5        3         1   \n",
      "124         0        1        3       23        2       10         0   \n",
      "125         1        0        1       22        7        0         1   \n",
      "\n",
      "      latitude  longitude  \n",
      "0      40.4406   -79.9959  \n",
      "1      40.4406   -79.9959  \n",
      "2      40.4406   -79.9959  \n",
      "114    29.7604   -95.3698  \n",
      "115    29.7604   -95.3698  \n",
      "116    29.7604   -95.3698  \n",
      "117    29.7604   -95.3698  \n",
      "118    29.7604   -95.3698  \n",
      "119    29.7604   -95.3698  \n",
      "1999   32.7157  -117.1611  \n",
      "2000   32.7157  -117.1611  \n",
      "2001   32.7157  -117.1611  \n",
      "2055   34.0522  -118.2437  \n",
      "2056   34.0522  -118.2437  \n",
      "120    29.7604   -95.3698  \n",
      "121    29.7604   -95.3698  \n",
      "122    29.7604   -95.3698  \n",
      "123    29.7604   -95.3698  \n",
      "124    29.7604   -95.3698  \n",
      "125    29.7604   -95.3698  \n",
      "\n",
      "[20 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming both venue_name columns are of the same data type\n",
    "\n",
    "\n",
    "# Merge the two DataFrames based on 'venue_name'\n",
    "merged_df = pd.merge(astro_df, location_df, on='city', how='inner')\n",
    "\n",
    "# 'inner' will keep only the rows where venue_name exists in both tables\n",
    "\n",
    "# Display the merged DataFrame\n",
    "\n",
    "# Sort merged_df by game_date\n",
    "merged_df = merged_df.sort_values(by='game_date')\n",
    "print(merged_df.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate distance from last game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/m7zq6dq13nvdg2z667851n9h0000gn/T/ipykernel_26571/3300626854.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df['distance'].iloc[i] = haversine(merged_df['latitude'].iloc[i-1], merged_df['longitude'].iloc[i-1], merged_df['latitude'].iloc[i], merged_df['longitude'].iloc[i])\n"
     ]
    }
   ],
   "source": [
    "# Add a column distance to the merged_df. Calculate the distance between the city in this row and the city in last row.\n",
    "# If the city in this row is the first city, then the distance is 0.\n",
    "# Use the function haversine() to calculate the distance.\n",
    "merged_df['distance'] = 0\n",
    "for i in range(1, len(merged_df)):\n",
    "    merged_df['distance'].iloc[i] = haversine(merged_df['latitude'].iloc[i-1], merged_df['longitude'].iloc[i-1], merged_df['latitude'].iloc[i], merged_df['longitude'].iloc[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change game_date to datetime\n",
    "merged_df['game_date'] = pd.to_datetime(merged_df['game_date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/m7zq6dq13nvdg2z667851n9h0000gn/T/ipykernel_26571/2674775903.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df['BABIP'].iloc[i] = (merged_df['away_1b'].iloc[i] + merged_df['away_2b'].iloc[i] + merged_df['away_3b'].iloc[i] - merged_df['away_hr'].iloc[i]) / (merged_df['away_pa'].iloc[i] - merged_df['away_bb'].iloc[i] - merged_df['away_hbp'].iloc[i] - merged_df['away_hr'].iloc[i] - merged_df['away_so'].iloc[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      game_date     BABIP\n",
      "0    2000-04-04  0.125000\n",
      "1    2000-04-05  0.347826\n",
      "2    2000-04-06  0.100000\n",
      "114  2000-04-07  0.125000\n",
      "115  2000-04-08  0.250000\n",
      "...         ...       ...\n",
      "3536 2023-09-26  0.333333\n",
      "3537 2023-09-27  0.258065\n",
      "2570 2023-09-29  0.347826\n",
      "2571 2023-09-30  0.260870\n",
      "2572 2023-10-01  0.192308\n",
      "\n",
      "[3784 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a column BABIP to the merged_df. Calculate the BABIP for each row.\n",
    "# BABIP = (home_1b + home_2b + home_3b - home_hr) / (home_pa - home_bb  - home_hbp - home_hr - home_so)\n",
    "# Iterate through rows, if HOU is home_team, extract all home_ data, if HOU is away_team, extract all away_ data\n",
    "\n",
    "merged_df['BABIP'] = 0\n",
    "\n",
    "for i in range(0, len(merged_df)):\n",
    "    if merged_df['home_team'].iloc[i] == 'HOU':\n",
    "        merged_df['BABIP'].iloc[i] = (merged_df['home_1b'].iloc[i] + merged_df['home_2b'].iloc[i] + merged_df['home_3b'].iloc[i] - merged_df['home_hr'].iloc[i]) / (merged_df['home_pa'].iloc[i] - merged_df['home_bb'].iloc[i] - merged_df['home_hbp'].iloc[i] - merged_df['home_hr'].iloc[i] - merged_df['home_so'].iloc[i])\n",
    "    else:\n",
    "        merged_df['BABIP'].iloc[i] = (merged_df['away_1b'].iloc[i] + merged_df['away_2b'].iloc[i] + merged_df['away_3b'].iloc[i] - merged_df['away_hr'].iloc[i]) / (merged_df['away_pa'].iloc[i] - merged_df['away_bb'].iloc[i] - merged_df['away_hbp'].iloc[i] - merged_df['away_hr'].iloc[i] - merged_df['away_so'].iloc[i])\n",
    "\n",
    "print(merged_df[['game_date', 'BABIP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         distance     BABIP  BABIP_average\n",
      "0        0.000000  0.125000       0.190942\n",
      "1        0.000000  0.347826       0.190942\n",
      "2        0.000000  0.100000       0.190942\n",
      "114   1829.889838  0.125000       0.143778\n",
      "115      0.000000  0.250000       0.143778\n",
      "116      0.000000  0.217391       0.143778\n",
      "117      0.000000 -0.047619       0.143778\n",
      "118      0.000000  0.160000       0.143778\n",
      "119      0.000000  0.157895       0.143778\n",
      "1999  2093.853720  0.166667       0.224786\n",
      "2000     0.000000  0.200000       0.224786\n",
      "2001     0.000000  0.307692       0.224786\n",
      "2055   179.410425  0.150000       0.259211\n",
      "2056     0.000000  0.368421       0.259211\n",
      "120   2206.264028  0.181818       0.195018\n",
      "121      0.000000  0.100000       0.195018\n",
      "122      0.000000  0.160000       0.195018\n",
      "123      0.000000  0.451613       0.195018\n",
      "124      0.000000  0.161290       0.195018\n",
      "125      0.000000  0.115385       0.195018\n"
     ]
    }
   ],
   "source": [
    "# Caculate the average BABIP of each specific time period.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_average_BABIP(df):\n",
    "    # Create a helper column to identify blocks\n",
    "    df['block'] = (df['distance'] != 0).cumsum()\n",
    "\n",
    "    # Calculating average score for each block\n",
    "    avg_scores = df.groupby('block')['BABIP'].mean()\n",
    "\n",
    "    # Mapping the average scores back to the original dataframe\n",
    "    df['BABIP_average'] = df['block'].map(avg_scores)\n",
    "\n",
    "    # Optionally, remove the helper column if it's no longer needed\n",
    "    df.drop('block', axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "merged_df = calculate_average_BABIP(merged_df)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "print(merged_df[['distance', 'BABIP', 'BABIP_average']].head(20))\n",
    "\n",
    "# Optionally, save the modified dataframe back to a CSV\n",
    "# df.to_csv('modified_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         distance  HOU_score\n",
      "0        0.000000          5\n",
      "1        0.000000         11\n",
      "2        0.000000          1\n",
      "114   1829.889838          1\n",
      "115      0.000000          8\n",
      "116      0.000000          2\n",
      "117      0.000000          7\n",
      "118      0.000000          6\n",
      "119      0.000000          7\n",
      "1999  2093.853720         10\n",
      "2000     0.000000          3\n",
      "2001     0.000000          3\n",
      "2055   179.410425          3\n",
      "2056     0.000000         10\n",
      "120   2206.264028          2\n",
      "121      0.000000          6\n",
      "122      0.000000         10\n",
      "123      0.000000         11\n",
      "124      0.000000          8\n",
      "125      0.000000          3\n",
      "2112  1618.872293          7\n",
      "2113     0.000000         10\n",
      "2114     0.000000          3\n",
      "2115     0.000000          5\n",
      "2230   131.055603          1\n",
      "2231     0.000000          3\n",
      "2232     0.000000          6\n",
      "2057  2803.971507          2\n",
      "2058     0.000000          6\n",
      "2059     0.000000         14\n",
      "126   2206.264028          1\n",
      "127      0.000000         13\n",
      "128      0.000000          5\n",
      "129      0.000000          3\n",
      "130      0.000000          7\n",
      "131      0.000000         10\n",
      "132      0.000000          3\n",
      "2116  1618.872293          5\n",
      "2379  1172.349177          2\n",
      "2380     0.000000          7\n",
      "2381     0.000000          3\n",
      "2117  1172.349177          9\n",
      "2118     0.000000          1\n",
      "133   1618.872293         10\n",
      "134      0.000000          7\n",
      "135      0.000000         10\n",
      "136      0.000000          5\n",
      "137      0.000000          5\n",
      "138      0.000000          4\n",
      "2397  1413.644844          7\n"
     ]
    }
   ],
   "source": [
    "# calculating the average point value of each specific time period (cities)\n",
    "\n",
    "# Iterate through rows, if HOU is home_team, extract home_consecutive_playing_days, if HOU is away_team, extract away_consecutive_playing_days\n",
    "# Add all consecutive_playing_days to a column hou_consecutive_playing_days\n",
    "merged_df['HOU_score'] = 0\n",
    "for index, row in merged_df.iterrows():\n",
    "    if row['home_team'] == 'HOU':\n",
    "        merged_df.loc[index, 'HOU_score'] = row['home_score']\n",
    "    else:\n",
    "        merged_df.loc[index, 'HOU_score'] = row['away_score']\n",
    "\n",
    "print(merged_df[[\"distance\",'HOU_score']].head(50))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         distance  HOU_score  HOU_AvgPoint\n",
      "0        0.000000          5      5.666667\n",
      "1        0.000000         11      5.666667\n",
      "2        0.000000          1      5.666667\n",
      "114   1829.889838          1      5.166667\n",
      "115      0.000000          8      5.166667\n",
      "116      0.000000          2      5.166667\n",
      "117      0.000000          7      5.166667\n",
      "118      0.000000          6      5.166667\n",
      "119      0.000000          7      5.166667\n",
      "1999  2093.853720         10      5.333333\n",
      "2000     0.000000          3      5.333333\n",
      "2001     0.000000          3      5.333333\n",
      "2055   179.410425          3      6.500000\n",
      "2056     0.000000         10      6.500000\n",
      "120   2206.264028          2      6.666667\n",
      "121      0.000000          6      6.666667\n",
      "122      0.000000         10      6.666667\n",
      "123      0.000000         11      6.666667\n",
      "124      0.000000          8      6.666667\n",
      "125      0.000000          3      6.666667\n"
     ]
    }
   ],
   "source": [
    "# calculating the average point of the HOU_score just received\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_hou_avg_point(df):\n",
    "    # Create a helper column to identify blocks\n",
    "    df['block'] = (df['distance'] != 0).cumsum()\n",
    "\n",
    "    # Calculating average score for each block\n",
    "    avg_scores = df.groupby('block')['HOU_score'].mean()\n",
    "\n",
    "    # Mapping the average scores back to the original dataframe\n",
    "    df['HOU_AvgPoint'] = df['block'].map(avg_scores)\n",
    "\n",
    "    # Optionally, remove the helper column if it's no longer needed\n",
    "    df.drop('block', axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "merged_df = calculate_hou_avg_point(merged_df)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "print(merged_df[['distance', 'HOU_score', 'HOU_AvgPoint']].head(20))\n",
    "\n",
    "# Optionally, save the modified dataframe back to a CSV\n",
    "# df.to_csv('modified_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         distance  HOU_AvgPoint  BABIP_average\n",
      "114   1829.889838      5.166667       0.143778\n",
      "1999  2093.853720      5.333333       0.224786\n",
      "2055   179.410425      6.500000       0.259211\n",
      "120   2206.264028      6.666667       0.195018\n",
      "2112  1618.872293      6.250000       0.198278\n",
      "2230   131.055603      3.333333       0.205000\n",
      "2057  2803.971507      7.333333       0.215873\n",
      "126   2206.264028      6.000000       0.196517\n",
      "2116  1618.872293      5.000000       0.227273\n",
      "2379  1172.349177      4.000000       0.190760\n",
      "2117  1172.349177      5.000000       0.234856\n",
      "133   1618.872293      6.833333       0.178715\n",
      "2397  1413.644844      6.666667       0.343701\n",
      "139   1413.644844      3.666667       0.243118\n",
      "2060  2206.264028      2.000000       0.100000\n",
      "2002   179.410425      3.666667       0.251804\n",
      "2400  1340.249516      6.000000       0.222203\n",
      "2455  1524.503301      4.000000       0.242853\n",
      "145   2643.045853      4.500000       0.284293\n",
      "2506  1632.166882      4.000000       0.295944\n",
      "2573  2043.754052      6.333333       0.186250\n",
      "151   1094.099848      5.666667       0.206599\n",
      "2681  1779.654964      5.666667       0.280920\n",
      "2720   145.133104      4.333333       0.233889\n",
      "157   1793.140904      6.400000       0.224670\n",
      "2759  1436.875034      5.666667       0.285538\n",
      "2861   595.451920      3.333333       0.301641\n",
      "2908   975.883024      3.750000       0.172540\n",
      "162   1556.794499      6.571429       0.282896\n",
      "2957  2156.270867      7.666667       0.278855\n",
      "169   2156.270867      8.000000       0.166884\n",
      "2382  2582.330426      4.666667       0.282390\n",
      "3003   533.688483      4.333333       0.240588\n",
      "178   2281.344820      7.000000       0.285824\n",
      "2233  1515.805107     11.333333       0.288767\n",
      "185   1515.805107      7.571429       0.271031\n",
      "2576  1094.099848      7.000000       0.301460\n",
      "2762   495.165236      4.000000       0.245965\n",
      "3      413.563833      5.333333       0.266865\n",
      "192   1829.889838      5.888889       0.240767\n",
      "2119  1618.872293      4.666667       0.199949\n",
      "2579   527.087186      5.333333       0.183631\n",
      "6      897.413345      2.000000       0.177931\n",
      "201   1829.889838      6.222222       0.257406\n",
      "3006  2281.344820      4.333333       0.136857\n",
      "2385   533.688483      8.333333       0.232168\n",
      "210   2582.330426      3.000000       0.144533\n",
      "2766  1436.875034      4.000000       0.222821\n",
      "2236   405.804738      6.333333       0.304689\n",
      "213   1515.805107      4.833333       0.246703\n"
     ]
    }
   ],
   "source": [
    "# Delete all rows with distance equals zero\n",
    "merged_df = merged_df[merged_df['distance'] != 0]\n",
    "print(merged_df[[\"distance\",'HOU_AvgPoint', 'BABIP_average']].head(50))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      " HOU_AvgPoint    14.218894\n",
      "BABIP            0.000000\n",
      "dtype: float64\n",
      "R-squared: 0.0009157291321006955\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare the data\n",
    "X = merged_df[['HOU_AvgPoint', 'BABIP']]  # Predictor variables (independent variables)\n",
    "y = merged_df['distance']  # Response variable (dependent variable)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit the Lasso Regression model to the dataset\n",
    "lasso = Lasso(alpha=10)  # Adjust the alpha value as needed\n",
    "lasso.fit(X_scaled, y)\n",
    "\n",
    "# Examine the coefficients\n",
    "coefficients = pd.Series(lasso.coef_, index=['HOU_AvgPoint', 'BABIP'])\n",
    "print(\"Coefficients:\\n\", coefficients)\n",
    "\n",
    "# Optional: Check the model's overall explanatory power\n",
    "r_squared = lasso.score(X_scaled, y)\n",
    "print(f\"R-squared: {r_squared}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
